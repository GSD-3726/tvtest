import asyncio
import http.cookies
import json
import re
import subprocess
import os
import requests
from time import time
from urllib.parse import quote, urljoin

import m3u8
from aiohttp import ClientSession, TCPConnector
from multidict import CIMultiDictProxy

# ==============================================
# ã€æ ¸å¿ƒé…ç½®åŒºã€‘å¯ç›´æ¥ä¿®æ”¹ï¼Œæ— éœ€æ”¹ä¸‹æ–¹ä»£ç 
# ==============================================
# è¿œç¨‹é“¾æ¥åœ°å€ï¼ˆgh-proxyåŠ é€Ÿçš„rawåœ°å€ï¼Œç¡®ä¿è·å–çº¯æ–‡æœ¬ï¼‰
REMOTE_URL = "https://gh-proxy.com/https://raw.githubusercontent.com/GSD-3726/IPTV/master/output/result.txt"
# è¾“å‡ºç›®å½•
OUTPUT_DIR = "output"
# ç”Ÿæˆæ–‡ä»¶å
TXT_FILENAME = "result.txt"
M3U_FILENAME = "iptv.m3u"
# è¯·æ±‚å¤´ï¼ˆé˜²åçˆ¬ï¼‰
REQUEST_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"
}
# é“¾æ¥åŒ¹é…æ­£åˆ™
URL_PATTERN = re.compile(r'https?://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]')

# ã€æµ‹é€Ÿé…ç½®ã€‘å¯æ ¹æ®éœ€æ±‚è°ƒæ•´
SPEED_TEST_TIMEOUT = 10  # å•é“¾æ¥æµ‹é€Ÿè¶…æ—¶ï¼ˆç§’ï¼‰
SPEED_TEST_FILTER_HOST = True  # æŒ‰åŸŸåç¼“å­˜æµ‹é€Ÿç»“æœ
OPEN_FILTER_RESOLUTION = True  # å¼€å¯åˆ†è¾¨ç‡è¿‡æ»¤
MIN_RESOLUTION = 720  # æœ€ä½åˆ†è¾¨ç‡ï¼ˆå®½ï¼‰
MAX_RESOLUTION = 2160  # æœ€é«˜åˆ†è¾¨ç‡ï¼ˆå®½ï¼‰
OPEN_FILTER_SPEED = True  # å¼€å¯é€Ÿåº¦è¿‡æ»¤
MIN_SPEED = 1  # æœ€ä½æœ‰æ•ˆé€Ÿåº¦ï¼ˆMB/sï¼‰
OPEN_SUPPLY = False  # å…³é—­å¤‡ç”¨æºå…¼å®¹
IPV6_SUPPORT = False  # å…³é—­IPv6ï¼ˆå¦‚éœ€å¼€å¯éœ€é…ç½®ä»£ç†ï¼‰

# å›ºå®šé…ç½®
M3U8_HEADERS = ['application/x-mpegurl', 'application/vnd.apple.mpegurl', 'audio/mpegurl', 'audio/x-mpegurl']
DEFAULT_IPV6_DELAY = 0.1
DEFAULT_IPV6_RES = "1920x1080"
DEFAULT_IPV6_RESULT = {'speed': float("inf"), 'delay': DEFAULT_IPV6_DELAY, 'resolution': DEFAULT_IPV6_RES}
http.cookies._is_legal_key = lambda _: True
CACHE = {}  # æµ‹é€Ÿå…¨å±€ç¼“å­˜

# ==============================================
# ã€å·¥å…·å‡½æ•°åŒºã€‘æ‹‰å–é“¾æ¥/ç”Ÿæˆæ–‡ä»¶/åˆå§‹åŒ–
# ==============================================
def init_output_dir():
    """åˆå§‹åŒ–è¾“å‡ºç›®å½•"""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    print(f"âœ… è¾“å‡ºç›®å½•åˆå§‹åŒ–å®Œæˆï¼š{OUTPUT_DIR}")

def get_remote_links() -> list[str]:
    """æ‹‰å–è¿œç¨‹txtä¸­çš„æ‰€æœ‰é“¾æ¥ï¼Œå»é‡å¹¶ä¿ç•™åŸé¡ºåº"""
    try:
        print(f"ğŸ” æ‹‰å–è¿œç¨‹é“¾æ¥ï¼š{REMOTE_URL}")
        resp = requests.get(REMOTE_URL, headers=REQUEST_HEADERS, timeout=30)
        resp.raise_for_status()
        links = list(dict.fromkeys(URL_PATTERN.findall(resp.text)))
        if not links:
            raise Exception("æœªåŒ¹é…åˆ°ä»»ä½•æœ‰æ•ˆé“¾æ¥")
        print(f"âœ… æˆåŠŸæ‹‰å– {len(links)} ä¸ªæœ‰æ•ˆé“¾æ¥")
        return links
    except Exception as e:
        print(f"âŒ æ‹‰å–é“¾æ¥å¤±è´¥ï¼š{str(e)}")
        raise SystemExit(1)

def save_txt(links: list[str]):
    """æŒ‰åŸæ ¼å¼ä¿å­˜TXTæ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªé“¾æ¥ï¼‰"""
    txt_path = os.path.join(OUTPUT_DIR, TXT_FILENAME)
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(links))
    print(f"âœ… TXTæ–‡ä»¶ç”Ÿæˆï¼š{txt_path}ï¼ˆ{len(links)}ä¸ªé“¾æ¥ï¼‰")

def save_m3u(links: list[str]):
    """ç”Ÿæˆæ ‡å‡†IPTV M3Uæ–‡ä»¶ï¼ˆé€‚é…VLC/TVBox/PotPlayerï¼Œå«EPGï¼‰"""
    m3u_path = os.path.join(OUTPUT_DIR, M3U_FILENAME)
    with open(m3u_path, 'w', encoding='utf-8') as f:
        f.write("#EXTM3U x-tvg-url=\"https://epg.112114.xyz/epg.xml.gz\"\n\n")
        for idx, link in enumerate(links, 1):
            f.write(f"#EXTINF:-1,IPTV Channel {idx}\n{link}\n\n")
    print(f"âœ… M3Uæ–‡ä»¶ç”Ÿæˆï¼š{m3u_path}ï¼ˆ{len(links)}ä¸ªé¢‘é“ï¼‰")

# ==============================================
# ã€æµ‹é€Ÿæ ¸å¿ƒåŒºã€‘ä¿ç•™æ‰€æœ‰åŸæµ‹é€Ÿä¼˜åŒ–é€»è¾‘
# ==============================================
def print_startup_info():
    """æ‰“å°å¯åŠ¨ä¿¡æ¯å’Œé…ç½®"""
    print("=" * 60)
    print("ğŸ¬ IPTVé“¾æ¥æ‹‰å–+æµ‹é€Ÿå·¥å…·ï¼ˆå•æ–‡ä»¶ç‰ˆï¼‰")
    print("=" * 60)
    print(f"ğŸ”§ è¿è¡Œé…ç½®ï¼š")
    print(f"   - è¿œç¨‹é“¾æ¥ï¼š{REMOTE_URL}")
    print(f"   - æµ‹é€Ÿè¶…æ—¶ï¼š{SPEED_TEST_TIMEOUT}ç§’ | æœ€ä½é€Ÿåº¦ï¼š{MIN_SPEED}MB/s")
    print(f"   - åˆ†è¾¨ç‡è¿‡æ»¤ï¼š{MIN_RESOLUTION}x~{MAX_RESOLUTION}x | åŸŸåç¼“å­˜ï¼š{'å¼€å¯' if SPEED_TEST_FILTER_HOST else 'å…³é—­'}")
    print(f"ğŸ“¦ ä¾èµ–æ£€æµ‹ï¼š")
    ffmpeg_ok = check_ffmpeg_installed_status()
    print(f"   - FFmpegï¼š{'âœ… å·²å®‰è£…' if ffmpeg_ok else 'âŒ æœªå®‰è£…ï¼ˆéƒ¨åˆ†åŠŸèƒ½å—é™ï¼‰'}")
    print("=" * 60 + "\n")

def check_ffmpeg_installed_status() -> bool:
    """æ£€æŸ¥FFmpegæ˜¯å¦å®‰è£…"""
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return True
    except (FileNotFoundError, Exception):
        return False

async def get_speed_with_download(url: str, headers: dict = None, session: ClientSession = None) -> dict:
    """ä¸‹è½½æµ‹é€Ÿï¼šè·å–å»¶è¿Ÿã€ä¸‹è½½å¤§å°ã€é€Ÿåº¦"""
    start_time = time()
    delay, total_size = -1, 0
    created_session = False
    if session is None:
        session = ClientSession(connector=TCPConnector(ssl=False), trust_env=True)
        created_session = True
    try:
        async with session.get(url, headers=headers, timeout=SPEED_TEST_TIMEOUT) as resp:
            if resp.status == 200:
                delay = int(round((time() - start_time) * 1000))
                async for chunk in resp.content.iter_any():
                    if chunk:
                        total_size += len(chunk)
    except:
        pass
    finally:
        total_time = max(time() - start_time, 0.001)  # é¿å…é™¤0
        speed = total_size / total_time / 1024 / 1024
        if created_session:
            await session.close()
        return {'speed': speed, 'delay': delay, 'size': total_size, 'time': total_time}

async def get_headers(url: str, headers: dict = None, session: ClientSession = None) -> dict:
    """è·å–URLå“åº”å¤´"""
    created_session = False
    if session is None:
        session = ClientSession(connector=TCPConnector(ssl=False), trust_env=True)
        created_session = True
    res_headers = {}
    try:
        async with session.head(url, headers=headers, timeout=5) as resp:
            res_headers = dict(resp.headers)
    except:
        pass
    finally:
        if created_session:
            await session.close()
        return res_headers

async def get_url_content(url: str, headers: dict = None, session: ClientSession = None) -> str:
    """è·å–URLæ–‡æœ¬å†…å®¹"""
    created_session = False
    if session is None:
        session = ClientSession(connector=TCPConnector(ssl=False), trust_env=True)
        created_session = True
    content = ""
    try:
        async with session.get(url, headers=headers, timeout=SPEED_TEST_TIMEOUT) as resp:
            if resp.status == 200:
                content = await resp.text()
    except:
        pass
    finally:
        if created_session:
            await session.close()
        return content

# ==============================================
# ã€æµ‹é€Ÿå…¥å£ã€‘get_speed å‡½æ•°å®šä¹‰
# ==============================================
async def get_speed(data: dict, headers: dict = None) -> dict:
    """å•é“¾æ¥æµ‹é€Ÿå…¥å£ï¼šå¸¦ç¼“å­˜"""
    url = data['url']
    result = {'speed': 0, 'delay': -1, 'resolution': None, 'url': url}
    use_headers = {**REQUEST_HEADERS, **(headers or {})}
    try:
        # ç”Ÿæˆç¼“å­˜keyï¼ˆåŸŸå/å®Œæ•´URLï¼‰
        cache_key = data.get('host') or url.split('/')[2] if SPEED_TEST_FILTER_HOST else url
        # ä»ç¼“å­˜è·å–
        if cache_key in CACHE:
            result = get_avg_result(CACHE[cache_key])
            result['url'] = url
        else:
            # IPv6å¤„ç†
            if data.get('ipv_type') == "ipv6" and IPV6_SUPPORT:
                result.update(DEFAULT_IPV6_RESULT)
            else:
                result.update(await get_result(url, use_headers))
            # åŠ å…¥ç¼“å­˜
            if cache_key:
                CACHE.setdefault(cache_key, []).append(result)
    finally:
        return result

# ==============================================
# ã€æ‰¹é‡æµ‹é€Ÿã€‘
# ==============================================
async def batch_speed_test(items: list[dict]) -> list[dict]:
    """æ‰¹é‡æµ‹é€Ÿå¹¶è¿”å›æœ‰æ•ˆé“¾æ¥"""
    global CACHE
    CACHE = {}  # æ¸…ç©ºç¼“å­˜
    # æ„é€ æµ‹é€Ÿä»»åŠ¡
    test_tasks = [{'name': item['name'], 'url': item['url'], 'host': item['url'].split('/')[2], 'ipv_type': 'ipv4'} for item in items]
    # å¼‚æ­¥æ‰¹é‡æµ‹é€Ÿ
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡æµ‹é€Ÿï¼ˆå…±{len(test_tasks)}ä¸ªé“¾æ¥ï¼‰")
    tasks = [get_speed(data) for data in test_tasks]
    test_results = await asyncio.gather(*tasks, return_exceptions=False)
    # è¿‡æ»¤æ’åº
    sorted_res = get_sort_result(test_results)
    valid_items = [{'name': res['name'], 'url': res['url']} for res in sorted_res]
    print(f"âœ… æµ‹é€Ÿå®Œæˆï¼Œä¿ç•™ {len(valid_items)} ä¸ªæœ‰æ•ˆé“¾æ¥\n")
    return valid_items

# ==============================================
# ã€ä¸»ç¨‹åºå…¥å£ã€‘
# ==============================================
async def main():
    """ä¸»æ‰§è¡Œæµç¨‹"""
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print_startup_info()
    # 1. åˆå§‹åŒ–ç›®å½•
    init_output_dir()
    # 2. æ‹‰å–è¿œç¨‹é“¾æ¥
    raw_links = get_remote_links()
    # 3. æ‰¹é‡æµ‹é€Ÿ
    valid_links = await batch_speed_test(raw_links)
    # 4. ç”Ÿæˆæ–‡ä»¶
    if valid_links:
        save_txt(valid_links)
        save_m3u(valid_links)
    else:
        print("âŒ æ— æœ‰æ•ˆé“¾æ¥ï¼Œæœªç”Ÿæˆæ–‡ä»¶")
    # æ‰§è¡Œå®Œæˆ
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼è¾“å‡ºæ–‡ä»¶åœ¨ï¼šoutput ç›®å½•")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
