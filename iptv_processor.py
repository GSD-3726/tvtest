import asyncio
import http.cookies
import json
import re
import subprocess
import os
import requests
from time import time
from urllib.parse import quote, urljoin, urlparse

import m3u8
from aiohttp import ClientSession, TCPConnector
from multidict import CIMultiDictProxy

# ==============================================
# ã€æ ¸å¿ƒé…ç½®åŒºã€‘å¯ç›´æ¥ä¿®æ”¹ï¼Œæ— éœ€æ”¹ä¸‹æ–¹ä»£ç 
# ==============================================
# è¿œç¨‹é“¾æ¥åœ°å€ï¼ˆgh-proxyåŠ é€Ÿçš„rawåœ°å€ï¼Œç¡®ä¿è·å–çº¯æ–‡æœ¬ï¼‰
REMOTE_URL = "https://gh-proxy.com/https://raw.githubusercontent.com/GSD-3726/IPTV/master/output/result.txt"
OUTPUT_DIR = "output"
TXT_FILENAME = "result.txt"
M3U_FILENAME = "iptv.m3u"
REQUEST_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"
}
URL_PATTERN = re.compile(r'https?://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]')

# æµ‹é€Ÿé…ç½®
SPEED_TEST_TIMEOUT = 10  # å•é“¾æ¥æµ‹é€Ÿè¶…æ—¶ï¼ˆç§’ï¼‰
SPEED_TEST_FILTER_HOST = True  # æŒ‰åŸŸåç¼“å­˜æµ‹é€Ÿç»“æœ
OPEN_FILTER_RESOLUTION = True  # å¼€å¯åˆ†è¾¨ç‡è¿‡æ»¤
MIN_RESOLUTION = 720  # æœ€ä½åˆ†è¾¨ç‡ï¼ˆå®½ï¼‰
MAX_RESOLUTION = 2160  # æœ€é«˜åˆ†è¾¨ç‡ï¼ˆå®½ï¼‰
OPEN_FILTER_SPEED = True  # å¼€å¯é€Ÿåº¦è¿‡æ»¤
MIN_SPEED = 1  # æœ€ä½æœ‰æ•ˆé€Ÿåº¦ï¼ˆMB/sï¼‰
SAMPLE_SEGMENTS = 5  # M3U8æŠ½æ ·ç‰‡æ®µæ•°é‡

# å›ºå®šé…ç½®
M3U8_HEADERS = ['application/x-mpegurl', 'application/vnd.apple.mpegurl', 'audio/mpegurl', 'audio/x-mpegurl']
DEFAULT_IPV6_DELAY = 0.1
DEFAULT_IPV6_RES = "1920x1080"
DEFAULT_IPV6_RESULT = {'speed': float("inf"), 'delay': DEFAULT_IPV6_DELAY, 'resolution': DEFAULT_IPV6_RES}
http.cookies._is_legal_key = lambda _: True
CACHE = {}  # æµ‹é€Ÿå…¨å±€ç¼“å­˜

# ==============================================
# ã€å·¥å…·å‡½æ•°åŒºã€‘æ‹‰å–é“¾æ¥/ç”Ÿæˆæ–‡ä»¶/åˆå§‹åŒ–
# ==============================================
def init_output_dir():
    """åˆå§‹åŒ–è¾“å‡ºç›®å½•"""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    print(f"âœ… è¾“å‡ºç›®å½•åˆå§‹åŒ–å®Œæˆï¼š{OUTPUT_DIR}")

def parse_result_file(url: str) -> list[dict]:
    """è§£æè¿œç¨‹æ–‡æœ¬æ–‡ä»¶ï¼Œè¿”å›åŒ…å«{'name', 'url'}çš„å­—å…¸åˆ—è¡¨"""
    items = []
    try:
        print(f"ğŸ” æ­£åœ¨æ‹‰å–è¿œç¨‹æ–‡ä»¶ï¼š{url}")
        resp = requests.get(url, headers=REQUEST_HEADERS, timeout=30)
        resp.raise_for_status()
        file_content = resp.text

        # è§£ææ–‡ä»¶å†…å®¹
        for line in file_content.splitlines():
            line = line.strip()
            if not line or '#genre#' in line:
                continue
            if ',' not in line:
                continue
            parts = line.split(',', 1)
            if len(parts) < 2:
                continue
            name, url = parts
            items.append({'name': name.strip(), 'url': url.strip()})

        if not items:
            raise ValueError("æœªåŒ¹é…åˆ°ä»»ä½•æœ‰æ•ˆé“¾æ¥")
        print(f"âœ… æˆåŠŸè§£ææ–‡ä»¶ï¼Œæ‰¾åˆ° {len(items)} ä¸ªæœ‰æ•ˆé“¾æ¥")
    except Exception as e:
        print(f"âŒ è§£ææ–‡ä»¶å¤±è´¥ï¼š{e}")
        raise SystemExit(1)

    return items

def save_txt(items: list[dict]):
    """ä¿å­˜é“¾æ¥åˆ° TXT æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªé“¾æ¥ï¼‰"""
    txt_path = os.path.join(OUTPUT_DIR, TXT_FILENAME)
    with open(txt_path, 'w', encoding='utf-8') as f:
        for item in items:
            f.write(f"{item['name']},{item['url']}\n")
    print(f"âœ… TXTæ–‡ä»¶ç”Ÿæˆï¼š{txt_path}ï¼ˆ{len(items)}ä¸ªé“¾æ¥ï¼‰")

def save_m3u(items: list[dict]):
    """ç”Ÿæˆæ ‡å‡†IPTV M3Uæ–‡ä»¶ï¼ˆé€‚é…VLC/TVBox/PotPlayerï¼Œå«EPGï¼‰"""
    m3u_path = os.path.join(OUTPUT_DIR, M3U_FILENAME)
    with open(m3u_path, 'w', encoding='utf-8') as f:
        f.write("#EXTM3U x-tvg-url=\"https://epg.112114.xyz/epg.xml.gz\"\n\n")
        for idx, item in enumerate(items, 1):
            f.write(f"#EXTINF:-1,{item['name']}\n{item['url']}\n\n")
    print(f"âœ… M3Uæ–‡ä»¶ç”Ÿæˆï¼š{m3u_path}ï¼ˆ{len(items)}ä¸ªé¢‘é“ï¼‰")

# ==============================================
# ã€æµ‹é€Ÿæ ¸å¿ƒåŒºã€‘ä¼˜åŒ–æµ‹é€Ÿé€»è¾‘
# ==============================================
def print_startup_info():
    """æ‰“å°å¯åŠ¨ä¿¡æ¯å’Œé…ç½®"""
    print("=" * 60)
    print("ğŸ¬ IPTVé“¾æ¥æ‹‰å–+æµ‹é€Ÿå·¥å…·ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    print("=" * 60)
    print(f"ğŸ”§ è¿è¡Œé…ç½®ï¼š")
    print(f"   - è¿œç¨‹é“¾æ¥ï¼š{REMOTE_URL}")
    print(f"   - æµ‹é€Ÿè¶…æ—¶ï¼š{SPEED_TEST_TIMEOUT}ç§’ | æœ€ä½é€Ÿåº¦ï¼š{MIN_SPEED}MB/s")
    print(f"   - åˆ†è¾¨ç‡è¿‡æ»¤ï¼š{MIN_RESOLUTION}x~{MAX_RESOLUTION}x | åŸŸåç¼“å­˜ï¼š{'å¼€å¯' if SPEED_TEST_FILTER_HOST else 'å…³é—­'}")
    print(f"   - M3U8æŠ½æ ·ç‰‡æ®µï¼š{SAMPLE_SEGMENTS}ä¸ª")
    print("=" * 60 + "\n")

async def get_headers(url: str, headers: dict = None) -> CIMultiDictProxy:
    """è·å–é“¾æ¥å“åº”å¤´ï¼ˆå¼‚æ­¥ï¼‰ï¼Œç”¨äºåˆ¤æ–­å†…å®¹ç±»å‹ã€é‡å®šå‘"""
    if headers is None:
        headers = REQUEST_HEADERS.copy()
    async with ClientSession(connector=TCPConnector(ssl=False), trust_env=True) as session:
        try:
            async with session.head(url, headers=headers, timeout=SPEED_TEST_TIMEOUT, allow_redirects=True) as resp:
                return resp.headers
        except:
            # å¤´è¯·æ±‚å¤±è´¥åˆ™ç”¨getè¯·æ±‚è·å–å¤´
            async with session.get(url, headers=headers, timeout=SPEED_TEST_TIMEOUT, allow_redirects=True) as resp:
                return resp.headers

async def get_url_content(url: str, headers: dict = None) -> str:
    """è·å–é“¾æ¥æ–‡æœ¬å†…å®¹ï¼ˆå¼‚æ­¥ï¼‰ï¼Œç”¨äºè§£æm3u8"""
    if headers is None:
        headers = REQUEST_HEADERS.copy()
    try:
        async with ClientSession(connector=TCPConnector(ssl=False), trust_env=True) as session:
            async with session.get(url, headers=headers, timeout=SPEED_TEST_TIMEOUT) as resp:
                if resp.status == 200:
                    return await resp.text()
        return ""
    except:
        return ""

async def get_speed_with_download(url: str, headers: dict = None, session: ClientSession = None) -> dict:
    """ä¸‹è½½æµ‹é€Ÿï¼šè·å–å»¶è¿Ÿã€ä¸‹è½½å¤§å°ã€é€Ÿåº¦ï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    start_time = time()
    delay, total_size = -1, 0
    created_session = False
    
    if session is None:
        session = ClientSession(connector=TCPConnector(ssl=False), trust_env=True)
        created_session = True
    
    try:
        async with session.get(url, headers=headers, timeout=SPEED_TEST_TIMEOUT) as resp:
            if resp.status == 200:
                # è®°å½•é¦–å­—èŠ‚åˆ°è¾¾æ—¶é—´ï¼ˆå»¶è¿Ÿï¼‰
                delay = int(round((time() - start_time) * 1000))
                
                # æµå¼è¯»å–å†…å®¹
                async for chunk in resp.content.iter_chunked(8192):
                    if chunk:
                        total_size += len(chunk)
    except Exception as e:
        # å¿½ç•¥é”™è¯¯ï¼Œè¿”å›é»˜è®¤å€¼
        pass
    finally:
        total_time = max(time() - start_time, 0.001)  # é¿å…é™¤0
        speed = total_size / total_time / 1024 / 1024  # MB/s
        
        if created_session:
            await session.close()
            
        return {
            'speed': speed,
            'delay': delay,
            'size': total_size,
            'time': total_time
        }

async def get_result(url: str, headers: dict = None) -> dict:
    """å•é“¾æ¥æµ‹é€Ÿï¼šä¸‹è½½æµ‹é€Ÿ + åˆ†è¾¨ç‡ + m3u8è§£æï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    info = {
        'speed': 0,
        'delay': -1,
        'resolution': DEFAULT_IPV6_RES
    }
    
    try:
        # æ¸…ç†URLå‚æ•°
        clean_url = quote(url.split('$')[0], safe=':/?=&')
        
        # è·å–å“åº”å¤´
        res_headers = await get_headers(clean_url, headers)
        
        # å¤„ç†é‡å®šå‘
        if location := res_headers.get('Location'):
            return await get_result(location, headers)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºM3U8
        content_type = res_headers.get('Content-Type', '').lower()
        is_m3u8 = any(h in content_type for h in M3U8_HEADERS)
        
        if is_m3u8:
            # è·å–M3U8å†…å®¹
            content = await get_url_content(clean_url, headers)
            if not content:
                return info
            
            # è§£æM3U8
            m3u8_obj = m3u8.loads(content)
            
            # è·å–åˆ†è¾¨ç‡
            resolution = DEFAULT_IPV6_RES
            if m3u8_obj.playlists:
                # å¤šç ç‡æµï¼šé€‰æ‹©æœ€é«˜ç ç‡
                best_playlist = max(m3u8_obj.playlists, key=lambda p: p.stream_info.bandwidth)
                if best_playlist.stream_info.resolution:
                    w, h = best_playlist.stream_info.resolution
                    resolution = f"{w}x{h}"
                    
                # è·å–å­æ’­æ”¾åˆ—è¡¨
                sub_url = urljoin(clean_url, best_playlist.uri)
                sub_content = await get_url_content(sub_url, headers)
                if sub_content:
                    sub_m3u8 = m3u8.loads(sub_content)
                    segments = sub_m3u8.segments
                else:
                    segments = []
            else:
                # å•ç ç‡æµ
                segments = m3u8_obj.segments
                if m3u8_obj.stream_info and m3u8_obj.stream_info.resolution:
                    w, h = m3u8_obj.stream_info.resolution
                    resolution = f"{w}x{h}"
            
            info['resolution'] = resolution
            
            # æŠ½æ ·æµ‹é€Ÿç‰‡æ®µ
            if segments:
                # éšæœºé€‰æ‹©ç‰‡æ®µï¼ˆé¿å…é¡ºåºåå·®ï¼‰
                sample_count = min(SAMPLE_SEGMENTS, len(segments))
                sample_segments = segments[:sample_count]
                
                # åˆ›å»ºä¼šè¯å¤ç”¨è¿æ¥
                async with ClientSession(connector=TCPConnector(ssl=False), trust_env=True) as session:
                    tasks = []
                    for seg in sample_segments:
                        seg_url = urljoin(clean_url, seg.uri)
                        tasks.append(get_speed_with_download(seg_url, headers, session))
                    
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    
                    # è®¡ç®—æ€»é€Ÿåº¦å’Œæ€»æ—¶é—´
                    total_size = 0
                    total_time = 0
                    valid_delays = []
                    
                    for res in results:
                        if isinstance(res, dict) and res['time'] > 0:
                            total_size += res['size']
                            total_time += res['time']
                            if res['delay'] > 0:
                                valid_delays.append(res['delay'])
                    
                    # è®¡ç®—å¹³å‡é€Ÿåº¦ï¼ˆæ€»å¤§å°/æ€»æ—¶é—´ï¼‰
                    if total_time > 0:
                        info['speed'] = total_size / total_time / 1024 / 1024
                    
                    # è®¡ç®—å¹³å‡å»¶è¿Ÿ
                    if valid_delays:
                        info['delay'] = int(round(sum(valid_delays) / len(valid_delays)))
                    elif segments:
                        info['delay'] = int(round((time() - time()) * 1000))  # ç®€åŒ–å¤„ç†
            else:
                # æ— ç‰‡æ®µæ—¶ä½¿ç”¨ä¸»URLæµ‹é€Ÿ
                download_res = await get_speed_with_download(clean_url, headers)
                info.update({
                    'speed': download_res['speed'],
                    'delay': download_res['delay']
                })
        else:
            # éM3U8ç›´æ¥æµ‹é€Ÿ
            download_res = await get_speed_with_download(clean_url, headers)
            info.update({
                'speed': download_res['speed'],
                'delay': download_res['delay']
            })
            
    except Exception as e:
        # é”™è¯¯å¤„ç†
        pass
    
    return info

async def get_speed(data: dict) -> dict:
    """å•é“¾æ¥æµ‹é€Ÿå…¥å£ï¼ˆå°è£…ç¼“å­˜+æµ‹é€Ÿé€»è¾‘ï¼‰"""
    global CACHE
    name = data['name']
    url = data['url']
    host = data['host']
    headers = REQUEST_HEADERS.copy()

    # åŸŸåç¼“å­˜é€»è¾‘
    if SPEED_TEST_FILTER_HOST and host in CACHE:
        cached = CACHE[host]
        return {
            'name': name,
            'url': url,
            'host': host,
            'speed': cached['speed'],
            'delay': cached['delay'],
            'resolution': cached['resolution']
        }

    # æ‰§è¡Œå®é™…æµ‹é€Ÿ
    result = await get_result(url, headers)
    result.update({
        'name': name,
        'url': url,
        'host': host
    })

    # ç¼“å­˜ç»“æœ
    if SPEED_TEST_FILTER_HOST and result['speed'] >= MIN_SPEED:
        CACHE[host] = {
            'speed': result['speed'],
            'delay': result['delay'],
            'resolution': result['resolution']
        }

    return result

def get_sort_result(results: list[dict]) -> list[dict]:
    """è¿‡æ»¤å¹¶æ’åºæµ‹é€Ÿç»“æœï¼šæŒ‰é€Ÿåº¦ä»å¿«åˆ°æ…¢ï¼Œè¿‡æ»¤æ— æ•ˆé“¾æ¥"""
    valid_results = []
    
    for res in results:
        speed = res.get('speed') or 0
        delay = res.get('delay')
        reso = res.get('resolution')
        
        # è·³è¿‡æ— æ•ˆå»¶è¿Ÿ
        if delay == -1:
            continue
            
        # é€Ÿåº¦è¿‡æ»¤
        if OPEN_FILTER_SPEED and speed < MIN_SPEED:
            continue
            
        # åˆ†è¾¨ç‡è¿‡æ»¤
        if OPEN_FILTER_RESOLUTION and reso and reso != "éŸ³é¢‘æµ":
            try:
                # å¤„ç†åˆ†è¾¨ç‡æ ¼å¼ï¼ˆå¯èƒ½åŒ…å«ç©ºæ ¼ç­‰ï¼‰
                reso_clean = reso.replace(' ', '')
                if 'x' in reso_clean:
                    res_w = int(reso_clean.split('x')[0])
                    if res_w < MIN_RESOLUTION or res_w > MAX_RESOLUTION:
                        continue
            except:
                # è§£æå¤±è´¥ä¿ç•™
                pass
                
        valid_results.append(res)
    
    # æŒ‰é€Ÿåº¦é™åºæ’åºï¼Œé€Ÿåº¦ç›¸åŒåˆ™æŒ‰å»¶è¿Ÿå‡åº
    return sorted(
        valid_results, 
        key=lambda x: (-(x.get('speed') or 0), x.get('delay') or 9999)
    )

async def batch_speed_test(items: list[dict]) -> list[dict]:
    """æ‰¹é‡æµ‹é€Ÿå¹¶è¿”å›æœ‰æ•ˆé“¾æ¥"""
    global CACHE
    CACHE = {}  # æ¸…ç©ºç¼“å­˜
    
    # å‡†å¤‡æµ‹é€Ÿä»»åŠ¡
    test_tasks = []
    for item in items:
        try:
            parsed = urlparse(item['url'])
            host = parsed.netloc
            test_tasks.append({
                'name': item['name'],
                'url': item['url'],
                'host': host
            })
        except:
            continue
    
    # å¼‚æ­¥æ‰¹é‡æµ‹é€Ÿ
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡æµ‹é€Ÿï¼ˆå…±{len(test_tasks)}ä¸ªæœ‰æ•ˆä»»åŠ¡ï¼‰")
    tasks = [get_speed(data) for data in test_tasks]
    test_results = await asyncio.gather(*tasks, return_exceptions=False)
    
    # è¿‡æ»¤æ’åº
    sorted_res = get_sort_result(test_results)
    print(f"âœ… æµ‹é€Ÿå®Œæˆï¼Œä¿ç•™ {len(sorted_res)} ä¸ªæœ‰æ•ˆé“¾æ¥\n")
    return sorted_res

# ==============================================
# ã€ä¸»å‡½æ•°ã€‘
# ==============================================
async def main():
    """ä¸»æ‰§è¡Œæµç¨‹"""
    print_startup_info()
    init_output_dir()
    
    try:
        # 1. æ‹‰å–è¿œç¨‹æ–‡ä»¶é“¾æ¥
        items = parse_result_file(REMOTE_URL)
        
        # 2. æ‰¹é‡æµ‹é€Ÿ
        valid_items = await batch_speed_test(items)
        
        # 3. ç”Ÿæˆæ–‡ä»¶
        if valid_items:
            save_txt(valid_items)
            save_m3u(valid_items)
        else:
            print("âŒ æ— æœ‰æ•ˆé“¾æ¥ï¼Œæœªç”Ÿæˆæ–‡ä»¶")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼è¾“å‡ºæ–‡ä»¶åœ¨ï¼šoutput ç›®å½•")
    print("=" * 60)

if __name__ == "__main__":
    # é€‚é…Windowsç³»ç»Ÿasyncioäº‹ä»¶å¾ªç¯é—®é¢˜
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())
