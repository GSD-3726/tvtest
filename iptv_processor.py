import asyncio
import http.cookies
import json
import re
import subprocess
import os
import requests
from time import time
from urllib.parse import quote, urljoin

import m3u8
from aiohttp import ClientSession, TCPConnector
from multidict import CIMultiDictProxy

# ==============================================
# ã€æ ¸å¿ƒé…ç½®åŒºã€‘å¯ç›´æ¥ä¿®æ”¹ï¼Œæ— éœ€æ”¹ä¸‹æ–¹ä»£ç 
# ==============================================
# æœ¬åœ°æ–‡ä»¶è·¯å¾„æˆ–è¿œç¨‹é“¾æ¥
RESULT_FILE_PATH = '/mnt/data/result.txt'  # æœ¬åœ°æ–‡ä»¶è·¯å¾„
REMOTE_URL = "https://gh-proxy.com/https://raw.githubusercontent.com/GSD-3726/IPTV/master/output/result.txt"  # è¿œç¨‹é“¾æ¥
OUTPUT_DIR = "output"
TXT_FILENAME = "result.txt"
M3U_FILENAME = "iptv.m3u"
REQUEST_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"
}
URL_PATTERN = re.compile(r'https?://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]')

# æµ‹é€Ÿé…ç½®
SPEED_TEST_TIMEOUT = 10  # å•é“¾æ¥æµ‹é€Ÿè¶…æ—¶ï¼ˆç§’ï¼‰
SPEED_TEST_FILTER_HOST = True  # æŒ‰åŸŸåç¼“å­˜æµ‹é€Ÿç»“æœ
OPEN_FILTER_RESOLUTION = True  # å¼€å¯åˆ†è¾¨ç‡è¿‡æ»¤
MIN_RESOLUTION = 720  # æœ€ä½åˆ†è¾¨ç‡ï¼ˆå®½ï¼‰
MAX_RESOLUTION = 2160  # æœ€é«˜åˆ†è¾¨ç‡ï¼ˆå®½ï¼‰
OPEN_FILTER_SPEED = True  # å¼€å¯é€Ÿåº¦è¿‡æ»¤
MIN_SPEED = 1  # æœ€ä½æœ‰æ•ˆé€Ÿåº¦ï¼ˆMB/sï¼‰

# å›ºå®šé…ç½®
M3U8_HEADERS = ['application/x-mpegurl', 'application/vnd.apple.mpegurl', 'audio/mpegurl', 'audio/x-mpegurl']
DEFAULT_IPV6_DELAY = 0.1
DEFAULT_IPV6_RES = "1920x1080"
DEFAULT_IPV6_RESULT = {'speed': float("inf"), 'delay': DEFAULT_IPV6_DELAY, 'resolution': DEFAULT_IPV6_RES}
http.cookies._is_legal_key = lambda _: True
CACHE = {}  # æµ‹é€Ÿå…¨å±€ç¼“å­˜

# ==============================================
# ã€å·¥å…·å‡½æ•°åŒºã€‘æ‹‰å–é“¾æ¥/ç”Ÿæˆæ–‡ä»¶/åˆå§‹åŒ–
# ==============================================
def init_output_dir():
    """åˆå§‹åŒ–è¾“å‡ºç›®å½•"""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    print(f"âœ… è¾“å‡ºç›®å½•åˆå§‹åŒ–å®Œæˆï¼š{OUTPUT_DIR}")

def parse_result_file(file_path: str) -> list[dict]:
    """è§£ææœ¬åœ°æ–‡æœ¬æ–‡ä»¶ï¼Œè¿”å›åŒ…å«{'name', 'url'}çš„å­—å…¸åˆ—è¡¨"""
    items = []
    try:
        if file_path.startswith("http"):  # å¦‚æœæ˜¯URLï¼ˆè¿œç¨‹é“¾æ¥ï¼‰
            print(f"ğŸ” æ­£åœ¨æ‹‰å–è¿œç¨‹æ–‡ä»¶ï¼š{file_path}")
            resp = requests.get(file_path, headers=REQUEST_HEADERS, timeout=30)
            resp.raise_for_status()
            file_content = resp.text
        else:  # å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„
            print(f"ğŸ” æ­£åœ¨è¯»å–æœ¬åœ°æ–‡ä»¶ï¼š{file_path}")
            with open(file_path, 'r', encoding='utf-8') as f:
                file_content = f.read()

        # è§£ææ–‡ä»¶å†…å®¹
        for line in file_content.splitlines():
            line = line.strip()
            if not line or '#genre#' in line:
                continue
            if ',' not in line:
                continue
            name, url = line.split(',', 1)
            items.append({'name': name.strip(), 'url': url.strip()})

        if not items:
            raise ValueError("æœªåŒ¹é…åˆ°ä»»ä½•æœ‰æ•ˆé“¾æ¥")
        print(f"âœ… æˆåŠŸè§£ææ–‡ä»¶ï¼Œæ‰¾åˆ° {len(items)} ä¸ªæœ‰æ•ˆé“¾æ¥")
    except Exception as e:
        print(f"âŒ è§£ææ–‡ä»¶å¤±è´¥ï¼š{e}")
        raise SystemExit(1)

    return items

def save_txt(items: list[dict]):
    """ä¿å­˜é“¾æ¥åˆ° TXT æ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªé“¾æ¥ï¼‰"""
    txt_path = os.path.join(OUTPUT_DIR, TXT_FILENAME)
    with open(txt_path, 'w', encoding='utf-8') as f:
        for item in items:
            f.write(f"{item['name']},{item['url']}\n")
    print(f"âœ… TXTæ–‡ä»¶ç”Ÿæˆï¼š{txt_path}ï¼ˆ{len(items)}ä¸ªé“¾æ¥ï¼‰")

def save_m3u(items: list[dict]):
    """ç”Ÿæˆæ ‡å‡†IPTV M3Uæ–‡ä»¶ï¼ˆé€‚é…VLC/TVBox/PotPlayerï¼Œå«EPGï¼‰"""
    m3u_path = os.path.join(OUTPUT_DIR, M3U_FILENAME)
    with open(m3u_path, 'w', encoding='utf-8') as f:
        f.write("#EXTM3U x-tvg-url=\"https://epg.112114.xyz/epg.xml.gz\"\n\n")
        for idx, item in enumerate(items, 1):
            f.write(f"#EXTINF:-1,{item['name']}\n{item['url']}\n\n")
    print(f"âœ… M3Uæ–‡ä»¶ç”Ÿæˆï¼š{m3u_path}ï¼ˆ{len(items)}ä¸ªé¢‘é“ï¼‰")

# ==============================================
# ã€æµ‹é€Ÿæ ¸å¿ƒåŒºã€‘ä¿ç•™æ‰€æœ‰åŸæµ‹é€Ÿä¼˜åŒ–é€»è¾‘
# ==============================================
def print_startup_info():
    """æ‰“å°å¯åŠ¨ä¿¡æ¯å’Œé…ç½®"""
    print("=" * 60)
    print("ğŸ¬ IPTVé“¾æ¥æ‹‰å–+æµ‹é€Ÿå·¥å…·ï¼ˆå•æ–‡ä»¶ç‰ˆï¼‰")
    print("=" * 60)
    print(f"ğŸ”§ è¿è¡Œé…ç½®ï¼š")
    print(f"   - è¿œç¨‹é“¾æ¥ï¼š{RESULT_FILE_PATH}")
    print(f"   - æµ‹é€Ÿè¶…æ—¶ï¼š{SPEED_TEST_TIMEOUT}ç§’ | æœ€ä½é€Ÿåº¦ï¼š{MIN_SPEED}MB/s")
    print(f"   - åˆ†è¾¨ç‡è¿‡æ»¤ï¼š{MIN_RESOLUTION}x~{MAX_RESOLUTION}x | åŸŸåç¼“å­˜ï¼š{'å¼€å¯' if SPEED_TEST_FILTER_HOST else 'å…³é—­'}")
    print("=" * 60 + "\n")

# ==============================================
# ã€æµ‹é€Ÿæ ¸å¿ƒåŒºã€‘get_speedã€get_result å’Œæµ‹é€Ÿé€»è¾‘
# ==============================================

async def get_speed_with_download(url: str, headers: dict = None, session: ClientSession = None) -> dict:
    """ä¸‹è½½æµ‹é€Ÿï¼šè·å–å»¶è¿Ÿã€ä¸‹è½½å¤§å°ã€é€Ÿåº¦"""
    start_time = time()
    delay, total_size = -1, 0
    created_session = False
    if session is None:
        session = ClientSession(connector=TCPConnector(ssl=False), trust_env=True)
        created_session = True
    try:
        async with session.get(url, headers=headers, timeout=SPEED_TEST_TIMEOUT) as resp:
            if resp.status == 200:
                delay = int(round((time() - start_time) * 1000))
                async for chunk in resp.content.iter_any():
                    if chunk:
                        total_size += len(chunk)
    except:
        pass
    finally:
        total_time = max(time() - start_time, 0.001)  # é¿å…é™¤0
        speed = total_size / total_time / 1024 / 1024
        if created_session:
            await session.close()
        return {'speed': speed, 'delay': delay, 'size': total_size, 'time': total_time}

async def get_result(url: str, headers: dict = None) -> dict:
    """å•é“¾æ¥æµ‹é€Ÿï¼šä¸‹è½½æµ‹é€Ÿ + åˆ†è¾¨ç‡ + m3u8è§£æ"""
    info = {'speed': 0, 'delay': -1, 'resolution': None}
    try:
        url = quote(url, safe=':/?$&=@[]%').partition('$')[0]
        res_headers = await get_headers(url, headers)
        # å¤„ç†é‡å®šå‘
        if location := res_headers.get('Location'):
            return await get_result(location, headers)
        # è§£æm3u8æµ
        content = await get_url_content(url, headers)
        if content and any(h in res_headers.get('Content-Type', '').lower() for h in M3U8_HEADERS):
            m3u8_obj = m3u8.loads(content)
            segment_urls = []
            # å¤„ç†å¤šç ç‡m3u8ï¼Œé€‰æœ€é«˜ç ç‡
            if m3u8_obj.playlists:
                best_playlist = max(m3u8_obj.playlists, key=lambda p: p.stream_info.bandwidth)
                playlist_content = await get_url_content(urljoin(url, best_playlist.uri), headers)
                if playlist_content:
                    segment_urls = [urljoin(url, s.uri) for s in m3u8.loads(playlist_content).segments]
            else:
                segment_urls = [urljoin(url, s.uri) for s in m3u8_obj.segments]
            # æµ‹é€Ÿm3u8ç‰‡æ®µï¼ˆè·³è¿‡ç¬¬ä¸€ä¸ªåˆå§‹åŒ–ç‰‡æ®µï¼Œå–åç»­5ä¸ªï¼‰
            if segment_urls:
                sample_segs = segment_urls[1:6] if len(segment_urls) > 1 else segment_urls
                tasks = [get_speed_with_download(seg, headers) for seg in sample_segs]
                results = await asyncio.gather(*tasks, return_exceptions=True)
                # è¿‡æ»¤æœ‰æ•ˆç»“æœï¼ŒæŒ‰å¤§å°åŠ æƒè®¡ç®—
                valid_res = [r for r in results if isinstance(r, dict) and r['time'] > 0 and r['size'] > 0]
                if valid_res:
                    total_size = sum(r['size'] for r in valid_res)
                    weighted_time = sum((r['size']/total_size)*r['time'] for r in valid_res)
                    info['speed'] = total_size / weighted_time / 1024 / 1024
                    info['delay'] = int(round(sum(r['delay'] for r in valid_res if r['delay']>0)/len(valid_res)))
                else:
                    info['delay'] = int(round((time()-start_time)*1000))
        else:
            # ém3u8ç›´æ¥æµ‹é€Ÿ
            download_res = await get_speed_with_download(url, headers)
            info.update({'speed': download_res['speed'], 'delay': download_res['delay']})
    except:
        pass
    return info

async def get_speed(data: dict, headers: dict = None) -> dict:
    """å•é“¾æ¥æµ‹é€Ÿå…¥å£ï¼šå¸¦ç¼“å­˜"""
    url = data['url']
    result = {'speed': 0, 'delay': -1, 'resolution': None, 'url': url}
    use_headers = {**REQUEST_HEADERS, **(headers or {})}
    try:
        # ç”Ÿæˆç¼“å­˜keyï¼ˆåŸŸå/å®Œæ•´URLï¼‰
        cache_key = data.get('host') or url.split('/')[2] if SPEED_TEST_FILTER_HOST else url
        # ä»ç¼“å­˜è·å–
        if cache_key in CACHE:
            result = get_avg_result(CACHE[cache_key])
            result['url'] = url
        else:
            # IPv6å¤„ç†
            if data.get('ipv_type') == "ipv6" and IPV6_SUPPORT:
                result.update(DEFAULT_IPV6_RESULT)
            else:
                result.update(await get_result(url, use_headers))
            # åŠ å…¥ç¼“å­˜
            if cache_key:
                CACHE.setdefault(cache_key, []).append(result)
    finally:
        return result

async def batch_speed_test(items: list[dict]) -> list[dict]:
    """æ‰¹é‡æµ‹é€Ÿå¹¶è¿”å›æœ‰æ•ˆé“¾æ¥"""
    global CACHE
    CACHE = {}  # æ¸…ç©ºç¼“å­˜
    # æ„é€ æµ‹é€Ÿä»»åŠ¡
    test_tasks = [{'name': item['name'], 'url': item['url'], 'host': item['url'].split('/')[2], 'ipv_type': 'ipv4'} for item in items]
    # å¼‚æ­¥æ‰¹é‡æµ‹é€Ÿ
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡æµ‹é€Ÿï¼ˆå…±{len(test_tasks)}ä¸ªé“¾æ¥ï¼‰")
    tasks = [get_speed(data) for data in test_tasks]
    test_results = await asyncio.gather(*tasks, return_exceptions=False)
    # è¿‡æ»¤æ’åº
    sorted_res = get_sort_result(test_results)
    valid_links = [res['url'] for res in sorted_res]
    print(f"âœ… æµ‹é€Ÿå®Œæˆï¼Œä¿ç•™ {len(valid_links)} ä¸ªæœ‰æ•ˆé“¾æ¥\n")
    return valid_links

async def main():
    """ä¸»æ‰§è¡Œæµç¨‹"""
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print_startup_info()
    # 1. åˆå§‹åŒ–ç›®å½•
    init_output_dir()
    # 2. æ‹‰å–æœ¬åœ°æ–‡ä»¶é“¾æ¥
    items = parse_result_file(RESULT_FILE_PATH if RESULT_FILE_PATH else REMOTE_URL)
    # 3. æ‰¹é‡æµ‹é€Ÿ
    valid_links = await batch_speed_test(items)
    # 4. ç”Ÿæˆæ–‡ä»¶
    if valid_links:
        save_txt(valid_links)
        save_m3u(valid_links)
    else:
        print("âŒ æ— æœ‰æ•ˆé“¾æ¥ï¼Œæœªç”Ÿæˆæ–‡ä»¶")
    # æ‰§è¡Œå®Œæˆ
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼è¾“å‡ºæ–‡ä»¶åœ¨ï¼šoutput ç›®å½•")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
