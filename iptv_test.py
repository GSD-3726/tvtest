import requests
import time
import statistics
from urllib.parse import urljoin
from datetime import datetime

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰=====================
# åŸå§‹txtçš„RAWåœ°å€ï¼ˆè·³è¿‡GitHub blobé¡µé¢ï¼Œç›´æ¥è·å–çº¯æ–‡æœ¬ï¼‰
RAW_TXT_URL = "https://gh-proxy.com/https://raw.githubusercontent.com/GSD-3726/IPTV/master/output/result.txt"
OUTPUT_FILE = "result.txt"  # è¾“å‡ºåˆ°ä»“åº“æ ¹ç›®å½•ï¼Œæ–‡ä»¶åä¸åŸå§‹ä¸€è‡´
# æµ‹é€Ÿé…ç½®ï¼ˆå¹³è¡¡æµ·å¤–æœåŠ¡å™¨é€Ÿåº¦/å‡†ç¡®æ€§ï¼‰
TEST_SHARD_COUNT = 3  # m3u8åˆ†ç‰‡æµ‹è¯•æ•°é‡
TIMEOUT = 5           # å•æ¬¡è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
# å¡é¡¿åˆ¤å®šé˜ˆå€¼ï¼ˆé€‚é…æµ·å¤–æœåŠ¡å™¨è®¿é—®å›½å†…æºï¼‰
FAIL_RATE_THRESHOLD = 0.1   # å¤±è´¥ç‡â‰¤10%
AVG_TIME_THRESHOLD = 2.5    # å¹³å‡ä¸‹è½½è€—æ—¶â‰¤2.5ç§’
MAX_TIME_THRESHOLD = 6.0    # æœ€å¤§ä¸‹è½½è€—æ—¶â‰¤6ç§’
# æ”¯æŒçš„åè®®ï¼ˆUDPæ— æ³•é€šè¿‡HTTPæµ‹è¯•ï¼Œç›´æ¥è¿‡æ»¤ï¼‰
SUPPORTED_PROTOCOLS = ("http://", "https://")

# ===================== å·¥å…·å‡½æ•° =====================
def download_original_txt():
    """ä¸‹è½½åŸå§‹txtæ–‡ä»¶ï¼Œè¿”å›ã€åŸå§‹è¡Œåˆ—è¡¨ã€‘ï¼ˆä¿ç•™æ‰€æœ‰è¡¨æƒ…/ç¬¦å·/ç©ºæ ¼ï¼‰"""
    try:
        # æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚ï¼Œé¿å…è¢«æ‹¦æˆª
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        response = requests.get(RAW_TXT_URL, headers=headers, timeout=20)
        response.raise_for_status()  # æŠ›å‡ºHTTPé”™è¯¯
        response.encoding = "utf-8"  # å¼ºåˆ¶UTF-8ï¼Œä¿è¯ä¸­æ–‡/è¡¨æƒ…æ— ä¹±ç 
        # æŒ‰è¡Œåˆ†å‰²ï¼Œä¿ç•™åŸå§‹æ¢è¡Œç¬¦å¤–çš„æ‰€æœ‰æ ¼å¼ï¼ˆè¿‡æ»¤çº¯ç©ºè¡Œï¼‰
        original_lines = [line.rstrip('\n') for line in response.text.splitlines() if line.strip()]
        print(f"âœ… æˆåŠŸä¸‹è½½åŸå§‹æ–‡ä»¶ï¼Œå…±{len(original_lines)}è¡Œï¼ˆä¿ç•™æ‰€æœ‰åŸå§‹æ ¼å¼ï¼‰")
        return original_lines
    except Exception as e:
        print(f"âŒ ä¸‹è½½åŸå§‹txtå¤±è´¥ï¼š{str(e)}")
        return []

def parse_m3u8_shards(m3u8_url):
    """æ‰‹åŠ¨è§£æm3u8æ–‡ä»¶ï¼Œæå–tsåˆ†ç‰‡é“¾æ¥ï¼ˆä¸ä¾èµ–ç¬¬ä¸‰æ–¹åº“ï¼‰"""
    try:
        response = requests.get(m3u8_url, timeout=TIMEOUT)
        response.raise_for_status()
        base_url = m3u8_url.rsplit('/', 1)[0] + '/' if '/' in m3u8_url else ''
        shard_links = []
        for line in response.text.splitlines():
            line = line.strip()
            # è·³è¿‡æ³¨é‡Šè¡Œå’Œç©ºè¡Œï¼Œåªä¿ç•™tsåˆ†ç‰‡
            if line and not line.startswith('#') and line.endswith('.ts'):
                shard_links.append(urljoin(base_url, line))
        return shard_links if shard_links else None
    except Exception:
        return None

def test_stream_smoothness(play_url):
    """æµ‹è¯•å•ä¸ªæ’­æ”¾åœ°å€æ˜¯å¦å¡é¡¿ï¼ˆé€‚é…m3u8/flvï¼‰"""
    # è¿‡æ»¤ä¸æ”¯æŒçš„åè®®ï¼ˆUDPç­‰ï¼‰
    if not play_url.startswith(SUPPORTED_PROTOCOLS):
        return False
    
    # æµ‹è¯•m3u8æ ¼å¼
    if play_url.endswith('.m3u8'):
        shard_links = parse_m3u8_shards(play_url)
        if not shard_links:
            return False
        success_count = 0
        cost_times = []
        # æµ‹è¯•å‰Nä¸ªåˆ†ç‰‡
        for shard_url in shard_links[:TEST_SHARD_COUNT]:
            try:
                start_time = time.time()
                # æµå¼ä¸‹è½½å‰50KBï¼ŒéªŒè¯å¯ç”¨æ€§
                response = requests.get(shard_url, timeout=TIMEOUT, stream=True)
                response.raise_for_status()
                total_bytes = 0
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        total_bytes += len(chunk)
                        if total_bytes >= 51200:  # ä¸‹è½½50KBååœæ­¢
                            break
                cost_time = round(time.time() - start_time, 3)
                # è‡³å°‘ä¸‹è½½10KBè§†ä¸ºæˆåŠŸ
                if total_bytes >= 10240:
                    success_count += 1
                    cost_times.append(cost_time)
            except Exception:
                continue
        # æ— æˆåŠŸåˆ†ç‰‡åˆ™åˆ¤å®šå¡é¡¿
        if not cost_times:
            return False
        # è®¡ç®—åˆ¤å®šæŒ‡æ ‡
        fail_rate = (TEST_SHARD_COUNT - success_count) / TEST_SHARD_COUNT
        avg_time = statistics.mean(cost_times)
        max_time = max(cost_times)
        # åˆ¤å®šæ˜¯å¦æµç•…
        return (fail_rate <= FAIL_RATE_THRESHOLD and
                avg_time <= AVG_TIME_THRESHOLD and
                max_time <= MAX_TIME_THRESHOLD)
    
    # æµ‹è¯•flvæ ¼å¼
    elif play_url.endswith('.flv'):
        try:
            start_time = time.time()
            response = requests.get(play_url, timeout=TIMEOUT, stream=True)
            response.raise_for_status()
            # ä¸‹è½½å‰100KBéªŒè¯
            total_bytes = 0
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    total_bytes += len(chunk)
                    if total_bytes >= 102400:
                        break
            cost_time = round(time.time() - start_time, 3)
            # è‡³å°‘ä¸‹è½½10KBä¸”è€—æ—¶â‰¤æœ€å¤§é˜ˆå€¼è§†ä¸ºæµç•…
            return total_bytes >= 10240 and cost_time <= MAX_TIME_THRESHOLD
        except Exception:
            return False
    
    # å…¶ä»–æ ¼å¼ï¼ˆém3u8/flvï¼‰ç›´æ¥åˆ¤å®šä¸ºå¡é¡¿
    else:
        return False

# ===================== ä¸»é€»è¾‘ï¼šä¸¥æ ¼æŒ‰åŸå§‹æ ¼å¼å¤„ç† =====================
def main():
    print("="*70)
    print(f"IPTVæºæµ‹é€Ÿå¼€å§‹ | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*70)
    
    # 1. ä¸‹è½½åŸå§‹txtï¼Œè·å–æ‰€æœ‰åŸå§‹è¡Œï¼ˆä¿ç•™æ ¼å¼ï¼‰
    original_lines = download_original_txt()
    if not original_lines:
        print("âŒ æ— åŸå§‹æ•°æ®ï¼Œç»ˆæ­¢æµç¨‹")
        return
    
    # 2. å¤„ç†æ¯ä¸€è¡Œï¼Œä¸¥æ ¼ä¿ç•™åŸå§‹æ ¼å¼
    output_lines = []
    total_test_url = 0
    smooth_url_count = 0
    current_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    for line in original_lines:
        # å¤„ç†ã€æ›´æ–°æ—¶é—´è¡Œã€‘ï¼šä¿ç•™ğŸ•˜ï¸+#genre#ï¼Œä»…æ›¿æ¢æ—¶é—´
        if line.startswith("ğŸ•˜ï¸") and "#genre#" in line:
            output_line = f"ğŸ•˜ï¸{current_datetime},#genre#"
            output_lines.append(output_line)
            print(f"ğŸ“… æ›´æ–°æ—¶é—´è¡Œï¼š{output_line}")
        
        # å¤„ç†ã€åˆ†ç±»è¡Œã€‘ï¼šå¦‚ğŸ“ºå¤®è§†é¢‘é“,#genre#ï¼Œå®Œå…¨ä¿ç•™åŸå§‹æ ¼å¼
        elif "#genre#" in line and not line.startswith("ğŸ•˜ï¸"):
            output_lines.append(line)
            print(f"\nğŸ“‹ åˆ†ç±»è¡Œï¼ˆä¿ç•™ï¼‰ï¼š{line}")
        
        # å¤„ç†ã€æ’­æ”¾åœ°å€è¡Œã€‘ï¼šåç§°,é“¾æ¥ æ ¼å¼ï¼Œæµ‹é€Ÿåç­›é€‰
        else:
            if "," not in line:
                continue  # éåç§°+é“¾æ¥æ ¼å¼ï¼Œè·³è¿‡ï¼ˆé¿å…æ— æ•ˆè¡Œï¼‰
            # ä»…åˆ†å‰²ç¬¬ä¸€ä¸ªé€—å·ï¼ˆé˜²æ­¢é“¾æ¥å«é€—å·å¯¼è‡´è§£æé”™è¯¯ï¼‰
            name_part, url_part = line.split(",", 1)
            name = name_part.strip()
            play_url = url_part.strip()
            total_test_url += 1
            print(f"[{total_test_url}] æµ‹è¯•ï¼š{name} | {play_url[:60]}...", end=" ")
            
            # æµ‹é€Ÿå¹¶åˆ¤å®šæ˜¯å¦ä¿ç•™
            if test_stream_smoothness(play_url):
                smooth_url_count += 1
                output_lines.append(line)  # å®Œå…¨ä¿ç•™åŸå§‹åœ°å€è¡Œæ ¼å¼
                print("âœ… æµç•…ï¼ˆä¿ç•™ï¼‰")
            else:
                print("âŒ å¡é¡¿/ä¸å¯ç”¨ï¼ˆè·³è¿‡ï¼‰")
    
    # 3. å†™å…¥ç»“æœåˆ°ä»“åº“æ ¹ç›®å½•çš„result.txtï¼ˆä¸¥æ ¼æŒ‰åŸå§‹æ ¼å¼ï¼‰
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        # æŒ‰åŸå§‹è¡Œçš„æ¢è¡Œæ ¼å¼å†™å…¥ï¼ˆæ¯è¡Œä¸€ä¸ªæ¡ç›®ï¼‰
        f.write("\n".join(output_lines))
    
    # 4. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("="*70)
    print(f"âœ… æµ‹é€Ÿå®Œæˆ | æ€»æµ‹è¯•åœ°å€ï¼š{total_test_url} | ä¿ç•™æµç•…åœ°å€ï¼š{smooth_url_count}")
    print(f"ğŸ“„ ç»“æœæ–‡ä»¶å·²ç”Ÿæˆï¼šä»“åº“æ ¹ç›®å½•/{OUTPUT_FILE}ï¼ˆæ ¼å¼ä¸åŸå§‹txtå®Œå…¨ä¸€è‡´ï¼‰")
    print("="*70)

if __name__ == "__main__":
    main()
