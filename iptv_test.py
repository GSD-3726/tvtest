import aiohttp
import asyncio
import time
import statistics
from urllib.parse import urljoin
from datetime import datetime
import requests

# ===================== æé€Ÿé…ç½®ï¼ˆæ ¸å¿ƒæé€Ÿï¼‰=====================
RAW_TXT_URL = "https://gh-proxy.com/https://raw.githubusercontent.com/GSD-3726/IPTV/master/output/result.txt"
OUTPUT_FILE = "result.txt"
# å¼‚æ­¥å¹¶å‘æ•°ï¼ˆæ ¹æ®æœåŠ¡å™¨æ€§èƒ½è°ƒæ•´ï¼Œå»ºè®®5-10ï¼‰
CONCURRENT_LIMIT = 8
# æµ‹é€Ÿé…ç½®ï¼ˆæ›´å°‘æ•°æ®ï¼Œæ›´å¿«éªŒè¯ï¼‰
TEST_SHARD_COUNT = 2  # m3u8ä»…æµ‹è¯•2ä¸ªåˆ†ç‰‡ï¼ˆåŸ3ä¸ªï¼‰
TIMEOUT_FAST = 2      # å¿«é€Ÿé¢„å¤„ç†è¶…æ—¶ï¼ˆç§’ï¼ŒåŸ5ï¼‰
TIMEOUT_DEEP = 3      # æ·±åº¦æµ‹é€Ÿè¶…æ—¶ï¼ˆç§’ï¼ŒåŸ5ï¼‰
# å¡é¡¿åˆ¤å®šé˜ˆå€¼ï¼ˆé€‚é…æé€Ÿæµ‹è¯•ï¼‰
FAIL_RATE_THRESHOLD = 0.1   # å¤±è´¥ç‡â‰¤10%
AVG_TIME_THRESHOLD = 2.0    # å¹³å‡è€—æ—¶â‰¤2ç§’ï¼ˆåŸ2.5ï¼‰
MAX_TIME_THRESHOLD = 4.0    # æœ€å¤§è€—æ—¶â‰¤4ç§’ï¼ˆåŸ6ï¼‰
# æ”¯æŒçš„åè®®
SUPPORTED_PROTOCOLS = ("http://", "https://")

# ===================== å¼‚æ­¥å·¥å…·å‡½æ•°ï¼ˆæ ¸å¿ƒæé€Ÿï¼‰=====================
async def async_head_check(session, url):
    """å¼‚æ­¥å¿«é€Ÿæ£€æµ‹é“¾æ¥æ˜¯å¦å¯è¾¾ï¼ˆHEADè¯·æ±‚ï¼Œä»…1-2KBæ•°æ®ï¼‰"""
    try:
        async with session.head(url, timeout=TIMEOUT_FAST, allow_redirects=True):
            return True
    except Exception:
        return False

async def async_download_small(session, url, max_bytes=10*1024):
    """å¼‚æ­¥ä¸‹è½½å°‘é‡æ•°æ®ï¼ˆéªŒè¯å¯ç”¨æ€§ï¼Œè¿”å›è€—æ—¶+æ˜¯å¦æˆåŠŸï¼‰"""
    try:
        start_time = time.time()
        async with session.get(url, timeout=TIMEOUT_DEEP) as resp:
            if resp.status != 200:
                return 0, False
            total_bytes = 0
            async for chunk in resp.content.iter_chunked(1024):
                total_bytes += len(chunk)
                if total_bytes >= max_bytes:
                    break
            cost_time = round(time.time() - start_time, 3)
            # è‡³å°‘ä¸‹è½½2KBè§†ä¸ºæˆåŠŸ
            return cost_time, total_bytes >= 2*1024
    except Exception:
        return 0, False

async def parse_m3u8_async(session, m3u8_url):
    """å¼‚æ­¥è§£æm3u8ï¼Œä»…è¿”å›å‰Nä¸ªåˆ†ç‰‡"""
    try:
        async with session.get(m3u8_url, timeout=TIMEOUT_DEEP) as resp:
            if resp.status != 200:
                return None
            text = await resp.text()
            base_url = m3u8_url.rsplit('/', 1)[0] + '/' if '/' in m3u8_url else ''
            shards = []
            for line in text.splitlines():
                line = line.strip()
                if line and not line.startswith('#') and line.endswith('.ts'):
                    shards.append(urljoin(base_url, line))
                    if len(shards) >= TEST_SHARD_COUNT:  # ä»…å–éœ€è¦çš„åˆ†ç‰‡æ•°
                        break
            return shards if shards else None
    except Exception:
        return None

async def test_m3u8_async(session, m3u8_url):
    """å¼‚æ­¥æµ‹è¯•m3u8æµç•…åº¦ï¼ˆå¹¶å‘æµ‹è¯•åˆ†ç‰‡ï¼‰"""
    shards = await parse_m3u8_async(session, m3u8_url)
    if not shards:
        return False
    # å¹¶å‘æµ‹è¯•æ‰€æœ‰åˆ†ç‰‡
    tasks = [async_download_small(session, shard) for shard in shards]
    results = await asyncio.gather(*tasks)
    # ç»Ÿè®¡æœ‰æ•ˆç»“æœ
    cost_times = [t for t, ok in results if ok]
    if not cost_times:
        return False
    fail_rate = (len(results) - len(cost_times)) / len(results)
    avg_time = statistics.mean(cost_times)
    max_time = max(cost_times)
    return (fail_rate <= FAIL_RATE_THRESHOLD and
            avg_time <= AVG_TIME_THRESHOLD and
            max_time <= MAX_TIME_THRESHOLD)

async def test_flv_async(session, flv_url):
    """å¼‚æ­¥æµ‹è¯•flvæµç•…åº¦ï¼ˆä»…ä¸‹è½½50KBï¼‰"""
    cost_time, ok = await async_download_small(session, flv_url, max_bytes=50*1024)
    return ok and cost_time <= MAX_TIME_THRESHOLD

async def test_url_async(session, name, url, result_queue):
    """å¼‚æ­¥æµ‹è¯•å•ä¸ªåœ°å€ï¼Œç»“æœå­˜å…¥é˜Ÿåˆ—"""
    print(f"æµ‹è¯•ä¸­ï¼š{name} | {url[:60]}...", end=" ")
    # ç¬¬ä¸€æ­¥ï¼šå¿«é€Ÿè¿‡æ»¤æ— æ•ˆé“¾æ¥
    if not await async_head_check(session, url):
        print("âŒ å¿«é€Ÿæ£€æµ‹å¤±è´¥ï¼ˆä¸å¯è¾¾ï¼‰")
        return
    # ç¬¬äºŒæ­¥ï¼šæ·±åº¦æµ‹é€Ÿ
    if url.endswith('.m3u8'):
        is_smooth = await test_m3u8_async(session, url)
    elif url.endswith('.flv'):
        is_smooth = await test_flv_async(session, url)
    else:
        is_smooth = False
    # ç»“æœå…¥é˜Ÿ
    if is_smooth:
        print("âœ… æµç•…ï¼ˆä¿ç•™ï¼‰")
        await result_queue.put((name, url))
    else:
        print("âŒ å¡é¡¿/ä¸æ”¯æŒï¼ˆè·³è¿‡ï¼‰")

# ===================== ä¸»é€»è¾‘ï¼ˆä¿ç•™åŸå§‹æ ¼å¼+æé€Ÿè¿è¡Œï¼‰=====================
def download_original_txt():
    """åŒæ­¥ä¸‹è½½åŸå§‹txtï¼ˆä»…ä¸€æ¬¡ï¼Œè€—æ—¶å¯å¿½ç•¥ï¼‰"""
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(RAW_TXT_URL, headers=headers, timeout=10)
        resp.raise_for_status()
        resp.encoding = "utf-8"
        return [line.rstrip('\n') for line in resp.text.splitlines() if line.strip()]
    except Exception as e:
        print(f"ä¸‹è½½åŸå§‹æ–‡ä»¶å¤±è´¥ï¼š{e}")
        return []

async def main_async():
    print("="*70)
    print(f"IPTVæé€Ÿæµ‹é€Ÿå¼€å§‹ | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"å¹¶å‘æ•°ï¼š{CONCURRENT_LIMIT} | è¶…æ—¶ï¼šå¿«é€Ÿ{TIMEOUT_FAST}s / æ·±åº¦{TIMEOUT_DEEP}s")
    print("="*70)
    
    # 1. ä¸‹è½½åŸå§‹txtï¼ˆä¿ç•™æ ¼å¼ï¼‰
    original_lines = download_original_txt()
    if not original_lines:
        print("âŒ æ— åŸå§‹æ•°æ®ï¼Œç»ˆæ­¢")
        return
    
    # 2. è§£æåŸå§‹è¡Œï¼Œåˆ†ç¦»åˆ†ç±»è¡Œ/åœ°å€è¡Œ
    genre_lines = []       # åˆ†ç±»è¡Œï¼ˆå¦‚ğŸ“ºå¤®è§†é¢‘é“,#genre#ï¼‰
    url_tasks = []         # å¾…æµ‹è¯•çš„åœ°å€ä»»åŠ¡ (name, url)
    update_time_line = ""  # æ›´æ–°æ—¶é—´è¡Œ
    current_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    for line in original_lines:
        if line.startswith("ğŸ•˜ï¸") and "#genre#" in line:
            update_time_line = f"ğŸ•˜ï¸{current_datetime},#genre#"
        elif "#genre#" in line and not line.startswith("ğŸ•˜ï¸"):
            genre_lines.append((len(url_tasks), line))  # è®°å½•åˆ†ç±»è¡Œä½ç½®
        elif "," in line:
            name, url = line.split(",", 1)
            name = name.strip()
            url = url.strip()
            if url.startswith(SUPPORTED_PROTOCOLS):
                url_tasks.append((name, url))
    
    # 3. å¼‚æ­¥å¹¶å‘æµ‹è¯•æ‰€æœ‰åœ°å€ï¼ˆæ ¸å¿ƒæé€Ÿï¼‰
    result_queue = asyncio.Queue()
    # åˆ›å»ºå¼‚æ­¥sessionï¼ˆå¤ç”¨è¿æ¥ï¼‰
    connector = aiohttp.TCPConnector(limit=CONCURRENT_LIMIT)
    async with aiohttp.ClientSession(connector=connector) as session:
        # åˆ›å»ºæ‰€æœ‰æµ‹è¯•ä»»åŠ¡
        tasks = [test_url_async(session, name, url, result_queue) for name, url in url_tasks]
        # å¹¶å‘æ‰§è¡Œ
        await asyncio.gather(*tasks)
    
    # 4. æ•´ç†æµ‹è¯•ç»“æœï¼ˆä¿ç•™åŸå§‹åˆ†ç±»ç»“æ„ï¼‰
    smooth_urls = []
    while not result_queue.empty():
        smooth_urls.append(await result_queue.get())
    # æŒ‰åŸå§‹é¡ºåºæ•´ç†è¾“å‡ºè¡Œ
    output_lines = [update_time_line] if update_time_line else []
    url_idx = 0
    # æ’å…¥åˆ†ç±»è¡Œ+å¯¹åº”åœ°å€
    for genre_pos, genre_line in sorted(genre_lines, key=lambda x: x[0]):
        output_lines.append(genre_line)
        # æ’å…¥è¯¥åˆ†ç±»ä¸‹çš„æµç•…åœ°å€
        while url_idx < len(smooth_urls) and url_idx <= genre_pos:
            name, url = smooth_urls[url_idx]
            output_lines.append(f"{name},{url}")
            url_idx += 1
    # è¡¥å……å‰©ä½™åœ°å€
    while url_idx < len(smooth_urls):
        name, url = smooth_urls[url_idx]
        output_lines.append(f"{name},{url}")
        url_idx += 1
    
    # 5. å†™å…¥ç»“æœï¼ˆä¸¥æ ¼åŒ¹é…åŸå§‹æ ¼å¼ï¼‰
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(output_lines))
    
    # 6. ç»Ÿè®¡è¾“å‡º
    print("="*70)
    print(f"âœ… æé€Ÿæµ‹é€Ÿå®Œæˆ | æ€»æµ‹è¯•åœ°å€ï¼š{len(url_tasks)} | ä¿ç•™æµç•…åœ°å€ï¼š{len(smooth_urls)}")
    print(f"ğŸ“„ ç»“æœæ–‡ä»¶ï¼š{OUTPUT_FILE}ï¼ˆæ ¼å¼ä¸åŸå§‹å®Œå…¨ä¸€è‡´ï¼‰")
    print("="*70)

if __name__ == "__main__":
    # é€‚é…Windows/Linuxå¼‚æ­¥è¿è¡Œ
    if asyncio.get_event_loop_policy().__class__.__name__ == "WindowsProactorEventLoopPolicy":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    # è¿è¡Œå¼‚æ­¥ä¸»é€»è¾‘
    asyncio.run(main_async())
