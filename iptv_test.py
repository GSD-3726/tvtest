import aiohttp
import asyncio
import time
import statistics
from urllib.parse import urljoin
from datetime import datetime
import requests
from aiohttp import ClientTimeout

# ===================== é€‚é…ã€æµ·å¤–è®¿é—®å›½å†…æºã€‘æ ¸å¿ƒé…ç½®ï¼ˆå…³é”®ï¼ï¼‰=====================
RAW_TXT_URL = "https://gh-proxy.com/https://raw.githubusercontent.com/GSD-3726/IPTV/master/output/result.txt"
OUTPUT_FILE = "result.txt"
CONCURRENT_LIMIT = 6  # è°ƒä½å¹¶å‘ï¼Œé¿å…è¢«å›½å†…æœåŠ¡å™¨å±è”½ï¼ˆæµ·å¤–ä¸“ç”¨ï¼‰
TEST_SHARD_COUNT = 2  # åˆ†ç‰‡æµ‹è¯•æ•°ï¼Œå…¼é¡¾é€Ÿåº¦å’Œå‡†ç¡®æ€§
# é€‚é…æµ·å¤–é«˜å»¶è¿Ÿï¼šå¤§å¹…æ”¾å®½è¶…æ—¶æ—¶é—´
TIMEOUT_LIGHT = 4     # è½»é‡æ£€æµ‹è¶…æ—¶ï¼ˆåŸ2ç§’ï¼Œæµ·å¤–è°ƒ4ç§’ï¼‰
TIMEOUT_DEEP = 5      # æ·±åº¦æµ‹é€Ÿè¶…æ—¶ï¼ˆåŸ3ç§’ï¼Œæµ·å¤–è°ƒ5ç§’ï¼‰
# é€‚é…æµ·å¤–è®¿é—®çš„æµç•…é˜ˆå€¼ï¼ˆæ ¸å¿ƒï¼šä¼˜å…ˆä¿è¯èƒ½æ’­æ”¾ï¼Œè€Œéæè‡´1080Pï¼‰
FAIL_RATE_THRESHOLD = 0.1    # å¤±è´¥ç‡â‰¤10%ï¼ˆåŸ5%ï¼‰
AVG_TIME_THRESHOLD = 3.0     # å¹³å‡è€—æ—¶â‰¤3ç§’ï¼ˆåŸ1.5ç§’ï¼Œé€‚é…è·¨å¢ƒå»¶è¿Ÿï¼‰
MAX_TIME_THRESHOLD = 6.0     # æœ€å¤§è€—æ—¶â‰¤6ç§’ï¼ˆåŸ4ç§’ï¼‰
MIN_HD_SHARD_SIZE = 81920    # åˆ†ç‰‡â‰¥80KBå³å¯ï¼ˆåŸ100KBï¼Œå…¼å®¹å›½å†…å‡†é«˜æ¸…æºï¼‰
SUPPORTED_PROTOCOLS = ("http://", "https://")
# å›½å†…æºè¯·æ±‚é‡è¯•æ¬¡æ•°
RETRY_TIMES = 1

# ===================== å·¥å…·å‡½æ•°ï¼šé€‚é…å›½å†…æº+æµ·å¤–è®¿é—® =====================
async def async_retry_request(coro, times=RETRY_TIMES):
    """è¯·æ±‚é‡è¯•æœºåˆ¶ï¼šå›½å†…æºå¶å°”æŠ½é£ï¼Œé‡è¯•1æ¬¡å³å¯"""
    for _ in range(times + 1):
        try:
            return await coro
        except Exception:
            continue
    return None

async def async_light_check(session, url):
    """å¼±åŒ–å‰ç½®è½»é‡æ£€æµ‹ï¼šå¤±è´¥ä¸ä¸¢å¼ƒï¼Œä»…åšå‚è€ƒ"""
    try:
        async with session.get(url, timeout=ClientTimeout(total=TIMEOUT_LIGHT)) as resp:
            await resp.content.read(2048)  # è½»é‡æ£€æµ‹è°ƒ2KBï¼Œæ›´ç¨³
            return resp.status in [200, 301, 302]
    except Exception:
        return False  # å¤±è´¥ä»…è¿”å›Falseï¼Œåç»­ç›´æ¥è¿›æ·±åº¦æµ‹é€Ÿ

async def async_download_hd(session, url, max_bytes):
    """å¼‚æ­¥ä¸‹è½½ï¼šé€‚é…å›½å†…æºï¼Œå¸¦è¶…æ—¶/é‡è¯•"""
    try:
        start_time = time.time()
        async with session.get(url, timeout=ClientTimeout(total=TIMEOUT_DEEP)) as resp:
            if resp.status not in [200, 301, 302]:
                return 0, False, 0
            total_bytes = 0
            async for chunk in resp.content.iter_chunked(1024):
                total_bytes += len(chunk)
                if total_bytes >= max_bytes:
                    break
            cost_time = round(time.time() - start_time, 3)
            # å›½å†…æºæ”¾å®½æœ‰æ•ˆåˆ¤å®šï¼šè‡³å°‘1KBå³å¯
            return cost_time, total_bytes >= 1024, total_bytes
    except Exception:
        return 0, False, 0

async def parse_m3u8_async(session, m3u8_url):
    """å¼‚æ­¥è§£æm3u8ï¼šå›½å†…æºå…¼å®¹ï¼Œå¸¦é‡è¯•"""
    result = await async_retry_request(session.get(m3u8_url, timeout=ClientTimeout(total=TIMEOUT_DEEP)))
    if not result or result.status not in [200, 301, 302]:
        return None
    text = await result.text()
    base_url = m3u8_url.rsplit('/', 1)[0] + '/' if '/' in m3u8_url else ''
    shards = []
    for line in text.splitlines():
        line = line.strip()
        if line and not line.startswith('#') and line.endswith('.ts'):
            shards.append(urljoin(base_url, line))
            if len(shards) >= TEST_SHARD_COUNT:
                break
    return shards if shards else None

async def test_m3u8_async(session, m3u8_url):
    """æµ‹è¯•m3u8ï¼šé€‚é…æµ·å¤–è®¿é—®å›½å†…æºï¼Œé˜ˆå€¼æ”¾å®½"""
    shards = await parse_m3u8_async(session, m3u8_url)
    if not shards:
        return False
    # å¹¶å‘æµ‹è¯•åˆ†ç‰‡
    tasks = [async_download_hd(session, shard, MIN_HD_SHARD_SIZE) for shard in shards]
    results = await asyncio.gather(*tasks)
    # ç»Ÿè®¡æœ‰æ•ˆç»“æœï¼ˆåˆ†ç‰‡â‰¥80KB+ä¸‹è½½æˆåŠŸï¼‰
    cost_times = []
    for t, ok, b in results:
        if ok and b >= MIN_HD_SHARD_SIZE:
            cost_times.append(t)
    if not cost_times:
        return False
    # é€‚é…æµ·å¤–çš„é˜ˆå€¼åˆ¤å®š
    fail_rate = (len(results) - len(cost_times)) / len(results)
    avg_time = statistics.mean(cost_times)
    max_time = max(cost_times)
    return (fail_rate <= FAIL_RATE_THRESHOLD and
            avg_time <= AVG_TIME_THRESHOLD and
            max_time <= MAX_TIME_THRESHOLD)

async def test_flv_async(session, flv_url):
    """æµ‹è¯•FLVï¼šå›½å†…æºä¸“ç”¨ï¼Œæ”¾å®½åˆ¤å®š"""
    cost_time, ok, total_bytes = await async_download_hd(session, flv_url, 102400)
    # FLVä»…éœ€ä¸‹è½½â‰¥10KB+è€—æ—¶â‰¤é˜ˆå€¼å³å¯ï¼ˆé€‚é…å›½å†…æºï¼‰
    return ok and total_bytes >= 10240 and cost_time <= MAX_TIME_THRESHOLD

async def test_url_async(session, name, url, result_queue):
    """æ ¸å¿ƒæµ‹è¯•é€»è¾‘ï¼šå¼±åŒ–å‰ç½®æ£€æµ‹ï¼Œå¤±è´¥ç›´æ¥è¿›æ·±åº¦æµ‹é€Ÿï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰"""
    print(f"æµ‹è¯•ä¸­ï¼š{name} | {url[:60]}...", end=" ")
    # æ­¥éª¤1ï¼šè½»é‡æ£€æµ‹ï¼ˆä»…å‚è€ƒï¼Œå¤±è´¥ä¸ä¸¢å¼ƒï¼‰
    light_ok = await async_light_check(session, url)
    if not light_ok:
        print("âš ï¸  è½»é‡æ£€æµ‹è¶…æ—¶ï¼Œè¿›å…¥æ·±åº¦æµ‹é€Ÿ...", end=" ")
    # æ­¥éª¤2ï¼šæ·±åº¦æµ‹é€Ÿï¼ˆæ— è®ºå‰ç½®æ£€æµ‹æ˜¯å¦æˆåŠŸï¼Œéƒ½æ‰§è¡Œï¼‰
    try:
        if url.endswith('.m3u8'):
            is_smooth = await test_m3u8_async(session, url)
        elif url.endswith('.flv'):
            is_smooth = await test_flv_async(session, url)
        else:
            is_smooth = False
            print("âŒ ém3u8/flvåè®®")
            return
    except Exception:
        is_smooth = False
        print("âŒ æ·±åº¦æµ‹é€Ÿå¼‚å¸¸")
        return
    # æ­¥éª¤3ï¼šç»“æœåˆ¤å®š
    if is_smooth:
        print("âœ… æµç•…ï¼ˆä¿ç•™ï¼‰")
        await result_queue.put((name, url))
    else:
        print("âŒ å¡é¡¿/ä½æ¸…ï¼ˆæµ·å¤–è®¿é—®å—é™ï¼‰")

# ===================== ä¸»é€»è¾‘ï¼šä¿ç•™åŸå§‹æ ¼å¼+æµ·å¤–é€‚é… =====================
def download_original_txt():
    """ä¸‹è½½åŸå§‹txtï¼šå¸¦å›½å†…ä»£ç†ï¼Œæ›´ç¨³"""
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Referer": "https://github.com/",
            "Accept-Language": "zh-CN,zh;q=0.9"
        }
        resp = requests.get(RAW_TXT_URL, headers=headers, timeout=20)
        resp.raise_for_status()
        resp.encoding = "utf-8"
        return [line.rstrip('\n') for line in resp.text.splitlines() if line.strip()]
    except Exception as e:
        print(f"âŒ ä¸‹è½½åŸå§‹æ–‡ä»¶å¤±è´¥ï¼š{e}")
        return []

async def main_async():
    print("="*70)
    print(f"IPTVæµ‹é€Ÿï¼ˆæµ·å¤–è®¿é—®å›½å†…æºä¸“ç”¨ï¼‰| {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"å¹¶å‘æ•°ï¼š{CONCURRENT_LIMIT} | è¶…æ—¶ï¼šè½»é‡{TIMEOUT_LIGHT}s / æ·±åº¦{TIMEOUT_DEEP}s")
    print("="*70)
    
    # 1. ä¸‹è½½åŸå§‹txtï¼ˆä¿ç•™æ‰€æœ‰æ ¼å¼ï¼‰
    original_lines = download_original_txt()
    if not original_lines:
        print("âŒ æ— åŸå§‹æ•°æ®ï¼Œç»ˆæ­¢æµç¨‹")
        return
    
    # 2. è§£æåŸå§‹è¡Œï¼šåˆ†ç¦»åˆ†ç±»/åœ°å€/æ›´æ–°æ—¶é—´
    genre_map = {}        # åˆ†ç±»è¡Œä½ç½®æ˜ å°„
    url_tasks = []        # å¾…æµ‹è¯•åœ°å€ [(name, url)]
    update_time_line = "" # æ›´æ–°æ—¶é—´è¡Œ
    current_datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    for line in original_lines:
        if line.startswith("ğŸ•˜ï¸") and "#genre#" in line:
            update_time_line = f"ğŸ•˜ï¸{current_datetime},#genre#"
        elif "#genre#" in line and not line.startswith("ğŸ•˜ï¸"):
            genre_map[len(url_tasks)] = line
        elif "," in line:
            name_part, url_part = line.split(",", 1)
            name = name_part.strip()
            url = url_part.strip()
            if url.startswith(SUPPORTED_PROTOCOLS):
                url_tasks.append((name, url))

    # 3. å¼‚æ­¥Sessioné…ç½®ï¼šã€å›½å†…æºä¸“ç”¨æ ¸å¿ƒé…ç½®ã€‘
    connector = aiohttp.TCPConnector(
        limit=CONCURRENT_LIMIT,
        verify_ssl=False,  # å…³é—­SSLéªŒè¯ï¼ˆå›½å†…å¾ˆå¤šæºè¯ä¹¦ä¸è§„èŒƒï¼Œæµ·å¤–è®¿é—®ä¼šæŠ¥é”™ï¼‰
        ttl_dns_cache=300  # DNSç¼“å­˜ï¼Œæå‡å›½å†…æºè®¿é—®é€Ÿåº¦
    )
    # æ¨¡æ‹Ÿå›½å†…æµè§ˆå™¨è¯·æ±‚å¤´ï¼ˆé¿å…è¢«å›½å†…æºåœ°åŸŸå±è”½ï¼‰
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://www.baidu.com/",
        "Accept": "*/*",
        "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
        "Connection": "keep-alive",
        "Cache-Control": "no-cache"
    }
    # åˆ›å»ºSessionï¼šå¤ç”¨è¿æ¥+å›½å†…å¤´+å…³é—­SSL
    async with aiohttp.ClientSession(connector=connector, headers=headers) as session:
        result_queue = asyncio.Queue()
        # åˆ›å»ºæ‰€æœ‰æµ‹è¯•ä»»åŠ¡
        tasks = [test_url_async(session, n, u, result_queue) for n, u in url_tasks]
        await asyncio.gather(*tasks)

        # 4. æå–æµ‹è¯•ç»“æœ
        smooth_urls = []
        while not result_queue.empty():
            smooth_urls.append(await result_queue.get())

    # 5. æ•´ç†ç»“æœï¼šä¸¥æ ¼ä¿ç•™åŸå§‹åˆ†ç±»+é¡ºåº+æ ¼å¼
    output_lines = [update_time_line] if update_time_line else []
    current_url_idx = 0
    # æŒ‰åŸå§‹é¡ºåºæ’å…¥åˆ†ç±»è¡Œå’Œå¯¹åº”åœ°å€
    sorted_genre = sorted(genre_map.items(), key=lambda x: x[0])
    for idx, genre_line in sorted_genre:
        output_lines.append(genre_line)
        # æ’å…¥è¯¥åˆ†ç±»ä¸‹çš„æµç•…åœ°å€
        while current_url_idx < len(smooth_urls):
            url_pos = url_tasks.index(smooth_urls[current_url_idx]) if smooth_urls[current_url_idx] in url_tasks else -1
            if url_pos >= idx:
                n, u = smooth_urls[current_url_idx]
                output_lines.append(f"{n},{u}")
                current_url_idx += 1
            else:
                break
    # è¡¥å……å‰©ä½™æµç•…åœ°å€
    while current_url_idx < len(smooth_urls):
        n, u = smooth_urls[current_url_idx]
        output_lines.append(f"{n},{u}")
        current_url_idx += 1

    # 6. å†™å…¥ç»“æœï¼š1:1åŒ¹é…åŸå§‹txtæ ¼å¼ï¼ˆæ— ä»»ä½•å¤šä½™å­—ç¬¦ï¼‰
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(output_lines))

    # 7. ç»Ÿè®¡è¾“å‡º
    print("="*70)
    print(f"âœ… æµ‹é€Ÿå®Œæˆ | æ€»æµ‹è¯•åœ°å€ï¼š{len(url_tasks)} | ä¿ç•™æµç•…åœ°å€ï¼š{len(smooth_urls)}")
    print(f"ğŸ“„ ç»“æœæ–‡ä»¶ï¼šä»“åº“æ ¹ç›®å½•/{OUTPUT_FILE}ï¼ˆæ ¼å¼ä¸åŸå§‹å®Œå…¨ä¸€è‡´ï¼‰")
    print("="*70)

if __name__ == "__main__":
    # é€‚é…æ‰€æœ‰ç³»ç»Ÿï¼ˆWindows/Linux/Ubuntu/GitHub Actionsï¼‰
    try:
        if asyncio.get_event_loop_policy().__class__.__name__ == "WindowsProactorEventLoopPolicy":
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    except:
        pass
    asyncio.run(main_async())
